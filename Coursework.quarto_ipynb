{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Predicting Loan Defaults: A Data-Driven Approach to Credit Risk Analysis\"\n",
        "author: \"Student Number - 720017170\"\n",
        "subtitle: BEE2041 - Data Science in Economics\n",
        "format: pdf\n",
        "toc: true\n",
        "execute:\n",
        "    echo: false\n",
        "    warning: false\n",
        "    message: false\n",
        "    results: false\n",
        "header-includes:\n",
        "    - \\usepackage{float}  \n",
        "---"
      ],
      "id": "9cd98c25"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import matplotlib.patches as mpatches\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
        ")\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "import statsmodels.api as sm\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import resample\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from lightgbm import LGBMClassifier"
      ],
      "id": "359748d9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\\newpage\n",
        "## **1. Introduction**\n",
        "\n",
        "\n",
        "## **2. Data**\n"
      ],
      "id": "0bee2e45"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "loan_data = pd.read_csv('Loan_default.csv')\n",
        "# Data Cleaning\n",
        "# Drop duplicate rows if any\n",
        "loan_data.drop_duplicates(inplace=True)\n",
        "\n",
        "# Handle missing values (if there were any) - To median values\n",
        "loan_data.dropna()\n",
        "\n",
        "#Remove LoanID\n",
        "loan_data.drop(columns=['LoanID'], inplace=True)\n",
        "\n",
        "# Turn into categorical\n",
        "loan_data['NumCreditLines'] = loan_data['NumCreditLines'].astype('category')\n",
        "loan_data['LoanTerm'] = loan_data['LoanTerm'].astype('category')\n",
        "loan_data['Default'] = loan_data['Default'].astype('category')\n",
        "\n",
        "# Calculate distribution before downsampling\n",
        "default_counts_before = loan_data['Default'].value_counts()\n",
        "\n",
        "# Balance the classes in the Default column\n",
        "default_0 = loan_data[loan_data['Default'] == 0]\n",
        "default_1 = loan_data[loan_data['Default'] == 1]\n",
        "\n",
        "# Downsample majority class\n",
        "default_0_downsampled = resample(default_0, \n",
        "                                 replace=False,    \n",
        "                                 n_samples=len(default_1),  \n",
        "                                 random_state=123)\n",
        "\n",
        "# Combine minority class with downsampled majority class\n",
        "loan_data_balanced = pd.concat([default_0_downsampled, default_1])\n",
        "\n",
        "# Calculate distribution after downsampling\n",
        "default_counts_after = loan_data_balanced['Default'].value_counts()\n",
        "\n",
        "# Reduce the sample size to 1% of the balanced dataset while maintaining class proportions\n",
        "loan_data, _ = train_test_split(loan_data_balanced, test_size=0.90, stratify=loan_data_balanced['Default'], random_state=123)\n",
        "\n",
        "\n",
        "# Create a DataFrame for plotting\n",
        "distribution_df = pd.DataFrame({\n",
        "    'Before Downsampling': default_counts_before,\n",
        "    'After Downsampling': default_counts_after\n",
        "}).reset_index().melt(id_vars='Default', var_name='Stage', value_name='Count')"
      ],
      "id": "70940a42",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create a DataFrame with variable names and data types\n",
        "variable_info = pd.DataFrame({\n",
        "    'Variable': loan_data.columns,\n",
        "    'Data Type': loan_data.dtypes.astype(str)\n",
        "})\n",
        "\n",
        "# Add definitions for each variable\n",
        "variable_info['Definition'] = [\n",
        "    'Age of the borrower',\n",
        "    'Income of the borrower',\n",
        "    'Loan amount requested by the borrower',\n",
        "    'Credit score of the borrower',\n",
        "    'Number of months the borrower has been employed',\n",
        "    'Number of credit lines the borrower has',\n",
        "    'Interest rate of the loan',\n",
        "    'Term of the loan in months',\n",
        "    'Debt-to-Income ratio of the borrower',\n",
        "    'Education level of the borrower',\n",
        "    'Employment type of the borrower',\n",
        "    'Marital status of the borrower',\n",
        "    'Whether the borrower has a mortgage',\n",
        "    'Whether the borrower has dependents',\n",
        "    'Purpose of the loan',\n",
        "    'Whether the borrower has a co-signer',\n",
        "    'Whether the borrower defaulted on the loan'\n",
        "]\n",
        "\n",
        "# Convert the DataFrame to LaTeX format with appropriate formatting\n",
        "variable_info_latex = variable_info.to_latex(index=False,\n",
        "                                             caption=\"Variable Information\",\n",
        "                                             label=\"Table 1:variable_info\",\n",
        "                                             column_format=\"lll\",\n",
        "                                             escape=False)\n",
        "variable_info_latex = variable_info_latex.replace(\"\\\\begin{table}\", \"\\\\begin{table}[H]\")\n",
        "\n",
        "\n",
        "# Save to a LaTeX file\n",
        "with open(\"variable_info_table.tex\", \"w\") as f:\n",
        "    f.write(variable_info_latex)"
      ],
      "id": "6856a4a3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\\input{variable_info_table.tex}\n",
        "\n",
        "\n",
        "### **2.1 Descriptive Statistics**"
      ],
      "id": "f0b568be"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Compute summary statistics\n",
        "summary_stats = loan_data.describe().transpose()\n",
        "summary_stats = summary_stats[['count', 'mean', '50%', 'std', 'min', 'max']]\n",
        "summary_stats.columns = ['N', 'Mean', 'Median', 'SD', 'Min', 'Max']\n",
        "summary_stats.index.name = \"Variable\"\n",
        "\n",
        "# Round values for better readability and format as strings for LaTeX output\n",
        "summary_stats = summary_stats.round(1).astype(str)\n",
        "\n",
        "# Convert index to column for better formatting\n",
        "summary_stats.reset_index(inplace=True)\n",
        "\n",
        "# Convert table to LaTeX format with formatting\n",
        "latex_table = summary_stats.to_latex(index=False,\n",
        "                                     caption=\"Summary Statistics of Numeric Variables\",\n",
        "                                     label=\"Table 2:summary_stats\",\n",
        "                                     column_format=\"lrrrrrr\",\n",
        "                                     escape=False)\n",
        "\n",
        "latex_table = latex_table.replace(\"\\\\begin{table}\", \"\\\\begin{table}[H]\")\n",
        "\n",
        "# Save to a LaTeX file\n",
        "with open(\"summary_table.tex\", \"w\") as f:\n",
        "    f.write(latex_table)"
      ],
      "id": "07df8b00",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\\input{summary_table.tex}\n",
        "\n",
        "### **2.2 Distribution Analysis**\n"
      ],
      "id": "887b85c5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "numeric_cols = loan_data.select_dtypes(include=[np.number]).columns\n",
        "num_cols = 4\n",
        "num_rows = int(np.ceil(len(numeric_cols) / num_cols))\n",
        "\n",
        "plt.rcParams.update({'font.size': 45})\n",
        "plt.figure(figsize=(50, 15 * num_rows))\n",
        "for i, col in enumerate(numeric_cols, 1):\n",
        "    plt.subplot(num_rows, num_cols, i)\n",
        "    loan_data[col].hist(bins=30, edgecolor='black')\n",
        "    plt.title(f'Histogram of {col}')\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.xticks(rotation=45)  # Tilt the x-axis labels by 45 degrees\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.figtext(0.5, -0.01, \"Figure ?: Histograms of all Numeric Variables\", ha=\"center\", fontsize=55)\n",
        "plt.show()\n",
        "plt.rcParams.update({'font.size': 14})"
      ],
      "id": "8bffa6a5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#Clearning pt 2\n",
        "# Convert string variables using Label Encoding into categorical\n",
        "categorical_cols = ['Education', 'EmploymentType', 'MaritalStatus', 'HasMortgage', 'HasDependents', 'LoanPurpose', 'HasCoSigner']\n",
        "label_encoders = {}\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    loan_data[col] = le.fit_transform(loan_data[col])\n",
        "    label_encoders[col] = le\n",
        "numeric_cols = ['Age', 'Income', 'LoanAmount', 'CreditScore', 'MonthsEmployed', 'NumCreditLines', 'InterestRate', 'LoanTerm', 'DTIRatio']"
      ],
      "id": "aab63b5b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "loan_data['NumCreditLines'] = loan_data['NumCreditLines'].astype(int)\n",
        "loan_data['LoanTerm'] = loan_data['LoanTerm'].astype(int)\n",
        "\n",
        "# Box plots for all numeric variables pre normalisation\n",
        "plt.rcParams.update({'font.size': 12})\n",
        "plt.figure(figsize=(12, 5))\n",
        "loan_data.boxplot()\n",
        "plt.figtext(0.5, -0.2, \"Figure ?: Box Plots of All Variables Before Normalisation\", ha=\"center\", fontsize=11)\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "id": "2083799a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#Normalisation using z-score normalisation\n",
        "numeric_cols = ['Age', 'Income', 'LoanAmount', 'CreditScore', 'MonthsEmployed', 'NumCreditLines', 'InterestRate', 'LoanTerm', 'DTIRatio']\n",
        "scaler = StandardScaler()\n",
        "loan_data[numeric_cols] = scaler.fit_transform(loan_data[numeric_cols])\n",
        "\n",
        "# Box plots for all numeric variables post normalisation\n",
        "plt.figure(figsize=(12,5))\n",
        "loan_data.boxplot()\n",
        "plt.figtext(0.5, -0.2, \"Figure ?: Box Plots of All Variables After Normalisation\", ha=\"center\", fontsize=11)\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "id": "5d34e78c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Plot the stacked bar plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='Stage', y='Count', hue='Default', data=distribution_df, palette='gray')\n",
        "plt.xlabel('Stage')\n",
        "plt.ylabel('Count')\n",
        "plt.figtext(0.5, -0.01, \"Figure ?: Distribution of Default Before and After Downsampling\", ha=\"center\", fontsize=11)\n",
        "plt.legend(title='Default', loc='upper right')\n",
        "plt.show()"
      ],
      "id": "dcab4b29",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **2.3 Correlation Analysis**\n"
      ],
      "id": "2993d59b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Correlation plot\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(loan_data.corr(method='spearman'), annot=True, cmap='Greys', fmt='.2f', linewidths=0.5)\n",
        "plt.figtext(0.5, -0.09, \"Figure ?: Correlation Plot of All Variables \", ha=\"center\", fontsize=11)\n",
        "plt.show()"
      ],
      "id": "17b38e0b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Feature Selection\n",
        "# Compute the correlation matrix\n",
        "corr_matrix = loan_data.corr(method='spearman')\n",
        "\n",
        "# Filter columns based on correlation with 'Default'\n",
        "target_corr = corr_matrix['Default']\n",
        "filtered_cols = target_corr[(target_corr >= 0.05) | (target_corr <= -0.05)].index.tolist()\n",
        "\n",
        "# Update the dataset to keep only the filtered columns\n",
        "loan_data = loan_data[filtered_cols]"
      ],
      "id": "70a6c6e3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **3. Results and Discussion**\n"
      ],
      "id": "22cab7f2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Split the data into test and train\n",
        "train_data, test_data = train_test_split(loan_data, test_size=0.2, random_state=123)\n",
        "# Prepare dataset\n",
        "X_train = train_data.drop(columns=['Default'])\n",
        "y_train = train_data['Default']\n",
        "X_test = test_data.drop(columns=['Default'])\n",
        "y_test = test_data['Default']"
      ],
      "id": "a499672d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **3.1 Random Forest**\n"
      ],
      "id": "8f66113e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Define the parameter grid for Grid Search\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'bootstrap': [True, False]\n",
        "}\n",
        "\n",
        "# Initialize Grid Search with Cross-Validation\n",
        "grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5, scoring='accuracy', verbose=0, n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters and best score\n",
        "best_params = grid_search.best_params_\n",
        "best_score = grid_search.best_score_\n",
        "\n",
        "# Train the best model\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "best_rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Make Predictions\n",
        "rf_predictions = best_rf_model.predict(X_test)\n",
        "rf_probabilities = best_rf_model.predict_proba(X_test)[:, 1]  # Extract probability for positive class\n",
        "\n",
        "# Compute Confusion Matrix\n",
        "conf_matrix_rf = confusion_matrix(y_test, rf_predictions)\n",
        "\n",
        "# Compute Performance Metrics\n",
        "accuracyRF = round(accuracy_score(y_test, rf_predictions), 3)\n",
        "precisionRF = round(precision_score(y_test, rf_predictions), 3)\n",
        "recallRF = round(recall_score(y_test, rf_predictions), 3)\n",
        "f1_scoreRF = round(f1_score(y_test, rf_predictions), 3)\n",
        "\n",
        "# Compute ROC Curve and AUC Score\n",
        "fpr_rf, tpr_rf, _ = roc_curve(y_test, rf_probabilities)\n",
        "auc_value_RF = round(auc(fpr_rf, tpr_rf), 3)"
      ],
      "id": "2c620a71",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Plot ROC Curve for Random Forest\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(fpr_rf, tpr_rf, color=\"black\", linewidth=2, label=f\"AUC: {auc_value_RF}\")\n",
        "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"grey\")  # Reference diagonal\n",
        "plt.xlabel(\"False Positive Rate (1 - Specificity)\")\n",
        "plt.ylabel(\"True Positive Rate (Sensitivity)\")\n",
        "plt.suptitle(\"Figure ?: ROC Curve for Random Forest Model\", y = 0.0005, fontsize=11)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "id": "0dc33696",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Convert Confusion Matrix to DataFrame for Visualization\n",
        "conf_df_rf = pd.DataFrame(conf_matrix_rf, index=[\"No Default\", \"Default\"],\n",
        "                          columns=[\"No Default\", \"Default\"])\n",
        "\n",
        "# Plot Confusion Matrix for Random Forest\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.heatmap(conf_df_rf, annot=True, fmt=\"d\", cmap=\"Greys\", linewidths=0.5, cbar=False, annot_kws={\"size\": 24})\n",
        "plt.xlabel(\"Predicted Class\")\n",
        "plt.ylabel(\"Actual Class\")\n",
        "plt.suptitle(\"Figure ?: Confusion Matrix for Random Forest Model\", y = 0.0005, fontsize=11)\n",
        "plt.show()"
      ],
      "id": "aeaba2f3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Importance values\n",
        "# Extract feature importances\n",
        "feature_importances = best_rf_model.feature_importances_\n",
        "features = X_train.columns\n",
        "\n",
        "# Create a DataFrame for plotting\n",
        "importance_df = pd.DataFrame({\n",
        "    'Feature': features,\n",
        "    'Importance': feature_importances\n",
        "})\n",
        "\n",
        "# Sort the DataFrame by importance values\n",
        "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Plot the feature importances\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='Importance', y='Feature', data=importance_df, palette=sns.color_palette(\"Greys\", n_colors=len(importance_df)), edgecolor='black')\n",
        "plt.xlabel('Importance')\n",
        "plt.ylabel('Feature')\n",
        "plt.title('Feature Importances from Random Forest Model')\n",
        "plt.show()"
      ],
      "id": "c1b8f6a8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **3.2 XGBoost**\n"
      ],
      "id": "e668b139"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Define the parameter grid for Grid Search\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'subsample': [0.8, 0.9, 1.0]\n",
        "}\n",
        "\n",
        "# Initialize Grid Search with Cross-Validation for XGBClassifier\n",
        "grid_search = GridSearchCV(XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42), param_grid, cv=5, scoring='accuracy', verbose=0, n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters and best score\n",
        "best_params = grid_search.best_params_\n",
        "best_score = grid_search.best_score_\n",
        "\n",
        "# Train the best model\n",
        "best_xgb_model = grid_search.best_estimator_\n",
        "best_xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Make Predictions\n",
        "xgb_predictions = best_xgb_model.predict(X_test)\n",
        "xgb_probabilities = best_xgb_model.predict_proba(X_test)[:, 1]  # Extract probability for positive class\n",
        "\n",
        "# Compute Confusion Matrix\n",
        "conf_matrix_xgb = confusion_matrix(y_test, xgb_predictions)\n",
        "\n",
        "# Compute Performance Metrics\n",
        "accuracyXGB = round(accuracy_score(y_test, xgb_predictions), 3)\n",
        "precisionXGB = round(precision_score(y_test, xgb_predictions), 3)\n",
        "recallXGB = round(recall_score(y_test, xgb_predictions), 3)\n",
        "f1_scoreXGB = round(f1_score(y_test, xgb_predictions), 3)\n",
        "\n",
        "# Compute ROC Curve and AUC Score\n",
        "fpr_xgb, tpr_xgb, _ = roc_curve(y_test, xgb_probabilities)\n",
        "auc_value_XGB = round(auc(fpr_xgb, tpr_xgb), 3)"
      ],
      "id": "cf934708",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Plot ROC Curve for XGBoost\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(fpr_xgb, tpr_xgb, color=\"black\", linewidth=2, label=f\"AUC: {auc_value_XGB}\")\n",
        "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"grey\")  # Reference diagonal\n",
        "plt.xlabel(\"False Positive Rate (1 - Specificity)\")\n",
        "plt.ylabel(\"True Positive Rate (Sensitivity)\")\n",
        "plt.suptitle(\"Figure ?: ROC Curve for XGBoost Model\", y = 0.0005, fontsize=11)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "id": "11a9578c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Convert Confusion Matrix to DataFrame for Visualization\n",
        "conf_df = pd.DataFrame(conf_matrix_xgb, index=[\"No Default\", \"Default\"],\n",
        "                       columns=[\"No Default\", \"Default\"])\n",
        "\n",
        "# Plot Confusion Matrix\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.heatmap(conf_df, annot=True, fmt=\"d\", cmap=\"Greys\", linewidths=0.5, cbar=False, annot_kws={\"size\": 24})\n",
        "plt.xlabel(\"Predicted Class\")\n",
        "plt.ylabel(\"Actual Class\")\n",
        "plt.suptitle(\"Figure ?: Confusion Matrix for SVM Model\", y = 0.0005, fontsize=11)\n",
        "plt.show()"
      ],
      "id": "72fed759",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Extract feature importances\n",
        "feature_importances = best_xgb_model.feature_importances_\n",
        "features = X_train.columns\n",
        "\n",
        "# Create a DataFrame for plotting\n",
        "importance_df = pd.DataFrame({\n",
        "    'Feature': features,\n",
        "    'Importance': feature_importances\n",
        "})\n",
        "\n",
        "# Sort the DataFrame by importance values\n",
        "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Plot the feature importances\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='Importance', y='Feature', data=importance_df, palette=sns.color_palette(\"Greys\", n_colors=len(importance_df)), edgecolor='black')\n",
        "plt.xlabel('Importance')\n",
        "plt.ylabel('Feature')\n",
        "plt.title('Feature Importances from XGBoost Model')\n",
        "plt.show()"
      ],
      "id": "15bb3a56",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **3.3 Light Gradient Boosting Machine (LGBM)**\n"
      ],
      "id": "6d2f8c31"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Define the parameter grid for Grid Search\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [3, 5, 7, 10],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'num_leaves': [20, 31, 40],\n",
        "    'subsample': [0.8, 0.9, 1.0]\n",
        "}\n",
        "\n",
        "# Initialize Grid Search with Cross-Validation for LGBMClassifier\n",
        "grid_search = GridSearchCV(LGBMClassifier(random_state=42), param_grid, cv=5, scoring='accuracy', verbose=0, n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters and best score\n",
        "best_params = grid_search.best_params_\n",
        "best_score = grid_search.best_score_\n",
        "\n",
        "# Train the best model\n",
        "best_lgbm_model = grid_search.best_estimator_\n",
        "best_lgbm_model.fit(X_train, y_train)\n",
        "\n",
        "# Make Predictions\n",
        "lgbm_predictions = best_lgbm_model.predict(X_test)\n",
        "lgbm_probabilities = best_lgbm_model.predict_proba(X_test)[:, 1]  # Extract probability for positive class\n",
        "\n",
        "# Compute Confusion Matrix\n",
        "conf_matrix_lgbm = confusion_matrix(y_test, lgbm_predictions)\n",
        "\n",
        "# Compute Performance Metrics\n",
        "accuracyLGBM = round(accuracy_score(y_test, lgbm_predictions), 3)\n",
        "precisionLGBM = round(precision_score(y_test, lgbm_predictions), 3)\n",
        "recallLGBM = round(recall_score(y_test, lgbm_predictions), 3)\n",
        "f1_scoreLGBM = round(f1_score(y_test, lgbm_predictions), 3)\n",
        "\n",
        "# Compute ROC Curve and AUC Score\n",
        "fpr_lgbm, tpr_lgbm, _ = roc_curve(y_test, lgbm_probabilities)\n",
        "auc_value_LGBM = round(auc(fpr_lgbm, tpr_lgbm), 3)"
      ],
      "id": "913a5abe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Plot ROC Curve for LightGBM\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(fpr_lgbm, tpr_lgbm, color=\"blue\", linewidth=2, label=f\"AUC: {auc_value_LGBM}\")\n",
        "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"red\")  # Reference diagonal\n",
        "plt.xlabel(\"False Positive Rate (1 - Specificity)\")\n",
        "plt.ylabel(\"True Positive Rate (Sensitivity)\")\n",
        "plt.title(\"ROC Curve for LightGBM Model\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "id": "c5b44ba1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Convert Confusion Matrix to DataFrame for Visualization\n",
        "conf_df_lgbm = pd.DataFrame(conf_matrix_lgbm, index=[\"No Default\", \"Default\"],\n",
        "                            columns=[\"No Default\", \"Default\"])\n",
        "\n",
        "# Plot Confusion Matrix for LightGBM\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.heatmap(conf_df_lgbm, annot=True, fmt=\"d\", cmap=\"Greys\", linewidths=0.5, cbar=False, annot_kws={\"size\": 24})\n",
        "plt.xlabel(\"Predicted Class\")\n",
        "plt.ylabel(\"Actual Class\")\n",
        "plt.title(\"Confusion Matrix for LightGBM Model\")\n",
        "plt.show()"
      ],
      "id": "73def2ff",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Extract feature importances\n",
        "feature_importances = best_lgbm_model.feature_importances_\n",
        "features = X_train.columns\n",
        "\n",
        "# Create a DataFrame for plotting\n",
        "importance_df = pd.DataFrame({\n",
        "    'Feature': features,\n",
        "    'Importance': feature_importances\n",
        "})\n",
        "\n",
        "# Sort the DataFrame by importance values\n",
        "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Plot the feature importances in black and white with black outlines\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='Importance', y='Feature', data=importance_df, palette=sns.color_palette(\"Greys\", n_colors=len(importance_df)), edgecolor='black')\n",
        "plt.xlabel('Importance')\n",
        "plt.ylabel('Feature')\n",
        "plt.title('Feature Importances from LightGBM Model')\n",
        "plt.show()"
      ],
      "id": "70d0f5bf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **3.4 Model Evaluation and Comparisons**\n"
      ],
      "id": "46914510"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create Accuracy DataFrame\n",
        "accuracy_df = pd.DataFrame({\n",
        "    \"Model\": [\"RF\", \"XGB\", \"LGBM\"],\n",
        "    \"Value\": [accuracyRF, accuracyXGB, accuracyLGBM]\n",
        "})\n",
        "\n",
        "# Create Bar Plot for Accuracy\n",
        "plt.figure(figsize=(8, 3))\n",
        "sns.barplot(x=\"Model\", y=\"Value\", data=accuracy_df, palette=\"gray\", edgecolor=\"black\")\n",
        "for index, row in accuracy_df.iterrows():\n",
        "    plt.text(index, row.Value + 0.02, round(row.Value, 3), ha=\"center\", fontsize=10)\n",
        "plt.ylim(0, 1)\n",
        "plt.xlabel(\"Model\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.figtext(0.5, -0.1, \"Figure ?: Accuracy for Each Model\", ha=\"center\", fontsize=11)\n",
        "plt.show()"
      ],
      "id": "0901f82b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create a DataFrame for Performance Metrics\n",
        "performance_df = pd.DataFrame({\n",
        "    \"Model\": [\"RF\", \"XGB\", \"LGBM\"],\n",
        "    \"Accuracy\": [accuracyRF, accuracyXGB, accuracyLGBM],\n",
        "    \"Precision\": [precisionRF, precisionXGB, precisionLGBM],\n",
        "    \"Recall\": [recallRF, recallXGB, recallLGBM],\n",
        "    \"F1_Score\": [f1_scoreRF, f1_scoreXGB, f1_scoreLGBM],\n",
        "    \"AUC\": [auc_value_RF, auc_value_XGB, auc_value_LGBM]\n",
        "})\n",
        "\n",
        "# Round values for better readability and format as strings for LaTeX output\n",
        "performance_df = performance_df.round(3).astype(str)\n",
        "\n",
        "# Convert the DataFrame to LaTeX format with appropriate formatting\n",
        "performance_latex = performance_df.to_latex(index=False,\n",
        "                                             caption=\"Performance Metrics for Each Model\",\n",
        "                                             label=\"Table 3 :performance_metrics\",\n",
        "                                             column_format=\"lrrrrrr\",\n",
        "                                             escape=False)\n",
        "\n",
        "# Replace underscores with LaTeX-safe versions\n",
        "performance_latex = performance_latex.replace(\"F1_Score\", \"F1\\\\_Score\")\n",
        "performance_latex = performance_latex.replace(\"AUC\", \"AUC\")\n",
        "performance_latex = performance_latex.replace(\"\\\\begin{table}\", \"\\\\begin{table}[H]\")\n",
        "\n",
        "# Save to a LaTeX file\n",
        "with open(\"performance_table.tex\", \"w\") as f:\n",
        "    f.write(performance_latex)"
      ],
      "id": "7e1f13f3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\\input{performance_table.tex}\n",
        "\n",
        "## **4. Conclusion**\n",
        "\n",
        "\n",
        "\n",
        "Link to Github Repository = https://github.com/JoshLG18/DSE-EMP-Project"
      ],
      "id": "e2ee26bd"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/Users/joshlegrice/Library/Python/3.13/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}